# PrismRAG Configuration File

# Model settings
model:
  base_model: "meta-llama/Llama-3.1-70b-instruct"
  max_length: 4096
  temperature: 1.0
  top_p: 0.9
  device: "auto"
  torch_dtype: "float16"

# Training settings
training:
  learning_rate: 1e-5
  batch_size: 4
  gradient_accumulation_steps: 8
  num_epochs: 3
  warmup_steps: 100
  weight_decay: 0.01
  max_grad_norm: 1.0
  save_steps: 500
  eval_steps: 500
  logging_steps: 100
  save_total_limit: 3

# Data generation settings
data_generation:
  # Seed data generation
  seed_data:
    max_samples_per_source: 1000
    min_passage_length: 200
    max_passage_length: 1000
    difficulty_level: 8
  
  # Distractor generation
  distractor:
    max_iterations: 5
    quality_threshold: 4
    batch_size: 16
    relevance_weight: 0.4
    distraction_weight: 0.4
    format_weight: 0.2
  
  # Strategic CoT generation
  strategic_cot:
    max_iterations: 10
    random_attempts: 6
    quality_threshold: 4
    batch_size: 8
    strategy_depth: 3

# Data sources configuration
data_sources:
  wikipedia:
    enabled: true
    num_pages: 1000
    min_words: 500
    max_words: 7000
    min_lines: 10
    max_lines: 1000
    chunk_size_min: 250
    chunk_size_max: 1000
    languages: ["en"]
    categories: ["science", "history", "technology", "culture"]
  
  web_search:
    enabled: true
    max_pages_per_query: 10
    max_words_per_page: 3000
    search_engines: ["google", "bing"]
    query_categories: ["news", "academic", "general_knowledge"]
    time_sensitive: true
  
  knowledge_graph:
    enabled: false
    sources: ["wikidata", "dbpedia"]
    max_entities: 500
    min_popularity: 100

# Evaluation settings
evaluation:
  benchmarks:
    - "crag"
    - "covidqa"
    - "delucionqa"
    - "emanual"
    - "expertqa"
    - "finqa"
    - "hagrid"
    - "hotpotqa"
    - "ms_marco"
    - "pubmedqa"
    - "tatqa"
    - "techqa"
  
  metrics:
    - "factuality_score"
    - "accuracy"
    - "hallucination_rate"
    - "missing_rate"
    - "completeness"
    - "relevance"
  
  llm_as_judge:
    enabled: true
    model: "gpt-4"
    temperature: 0.3
    max_tokens: 500

# Paths configuration
paths:
  data_dir: "data"
  raw_data_dir: "data/raw"
  processed_data_dir: "data/processed"
  training_data_dir: "data/training"
  model_dir: "models"
  output_dir: "outputs"
  cache_dir: "cache"
  log_dir: "logs"

# API keys (should be set in environment variables)
api_keys:
  openai: ${OPENAI_API_KEY}
  google_search: ${GOOGLE_SEARCH_API_KEY}
  serpapi: ${SERPAPI_API_KEY}
  huggingface: ${HUGGINGFACE_HUB_TOKEN}

# Logging configuration
logging:
  level: "INFO"
  use_wandb: true
  wandb_project: "prismrag"
  wandb_entity: null
  log_file: "prismrag.log"
  console_output: true

# Performance optimization
performance:
  use_gradient_checkpointing: true
  use_flash_attention: true
  mixed_precision: "fp16"
  dataloader_num_workers: 4
  prefetch_factor: 2
  pin_memory: true

# Experimental features
experimental:
  use_raft: false
  use_star: false
  use_llm_quoter: false
  enable_multilingual: false
  enable_domain_specific: false

# Version info
version: "1.0.0"
last_updated: "2025-01-19"