# PrismRAG Production Configuration
# Optimized for production deployment with scalability and reliability

# Model settings for production
model:
  base_model: "meta-llama/Llama-3.1-70b-instruct"
  max_length: 4096
  temperature: 0.7  # Lower temperature for more deterministic outputs
  top_p: 0.9
  device: "auto"
  torch_dtype: "float16"
  # Production-specific model settings
  trust_remote_code: true
  low_cpu_mem_usage: true
  use_safetensors: true

# Training settings optimized for production
training:
  learning_rate: 2e-5
  batch_size: 2  # Smaller batch size for stability
  gradient_accumulation_steps: 16  # Compensate for smaller batch size
  num_epochs: 4
  warmup_steps: 200
  weight_decay: 0.01
  max_grad_norm: 1.0
  save_steps: 1000
  eval_steps: 500
  logging_steps: 100
  save_total_limit: 5  # Keep more checkpoints in production
  # Production-specific training settings
  dataloader_drop_last: true
  remove_unused_columns: true
  group_by_length: true
  length_column_name: "length"

# Data generation with production optimizations
data_generation:
  # Seed data generation
  seed_data:
    max_samples_per_source: 2000
    min_passage_length: 300
    max_passage_length: 1200
    difficulty_level: 7  # Slightly easier for better quality
  
  # Distractor generation
  distractor:
    max_iterations: 3  # Fewer iterations for speed
    quality_threshold: 3.8  # Higher quality threshold
    batch_size: 8
    relevance_weight: 0.4
    distraction_weight: 0.4
    format_weight: 0.2
  
  # Strategic CoT generation
  strategic_cot:
    max_iterations: 8
    random_attempts: 4
    quality_threshold: 3.8  # Higher quality threshold
    batch_size: 4
    strategy_depth: 3

# Data sources configuration for production
data_sources:
  wikipedia:
    enabled: true
    num_pages: 2000  # More pages for diversity
    min_words: 600
    max_words: 8000
    min_lines: 15
    max_lines: 1200
    chunk_size_min: 300
    chunk_size_max: 1200
    languages: ["en"]
    categories: ["science", "history", "technology", "culture", "medicine", "economics"]
    # Production rate limiting
    requests_per_minute: 30
    retry_attempts: 3
    timeout_seconds: 30
  
  web_search:
    enabled: true
    max_pages_per_query: 8
    max_words_per_page: 4000
    search_engines: ["google", "bing"]
    query_categories: ["news", "academic", "general_knowledge", "technical"]
    time_sensitive: true
    # Production rate limiting
    requests_per_minute: 20
    retry_attempts: 3
    timeout_seconds: 45

# Evaluation settings for production monitoring
evaluation:
  benchmarks:
    - "hotpotqa"
    - "ms_marco"
    - "pubmedqa"
    - "crag"
    - "covidqa"
  
  metrics:
    - "factuality_score"
    - "accuracy"
    - "hallucination_rate"
    - "completeness"
    - "relevance"
  
  llm_as_judge:
    enabled: true
    model: "gpt-4"
    temperature: 0.2  # Lower temperature for consistent evaluation
    max_tokens: 400
    # Production evaluation settings
    evaluation_batch_size: 16
    evaluation_interval: 1000  # Evaluate every 1000 samples

# Paths configuration for production deployment
paths:
  data_dir: "/data/prismrag"
  raw_data_dir: "/data/prismrag/raw"
  processed_data_dir: "/data/prismrag/processed"
  training_data_dir: "/data/prismrag/training"
  model_dir: "/models/prismrag"
  output_dir: "/outputs/prismrag"
  cache_dir: "/cache/prismrag"
  log_dir: "/var/log/prismrag"
  # Backup directories
  backup_dir: "/backups/prismrag"
  snapshot_dir: "/snapshots/prismrag"

# API keys configuration for production
api_keys:
  openai: ${OPENAI_API_KEY}
  google_search: ${GOOGLE_SEARCH_API_KEY}
  serpapi: ${SERPAPI_API_KEY}
  huggingface: ${HUGGINGFACE_HUB_TOKEN}
  # Additional production API keys
  azure_openai: ${AZURE_OPENAI_API_KEY}
  aws_access_key: ${AWS_ACCESS_KEY_ID}
  aws_secret_key: ${AWS_SECRET_ACCESS_KEY}

# Enhanced logging configuration for production
logging:
  level: "INFO"
  use_wandb: true
  wandb_project: "prismrag-production"
  wandb_entity: null
  log_file: "prismrag-production.log"
  console_output: true
  # Production logging features
  log_rotation: true
  max_log_size: "100MB"
  backup_count: 10
  log_format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  # Monitoring integration
  enable_prometheus: true
  prometheus_port: 9090
  enable_health_checks: true
  health_check_port: 8080

# Performance optimization for production
performance:
  use_gradient_checkpointing: true
  use_flash_attention: true
  mixed_precision: "fp16"
  dataloader_num_workers: 8  # More workers for production
  prefetch_factor: 4
  pin_memory: true
  # Additional production optimizations
  use_cuda_graph: true
  use_tensor_parallel: true
  use_pipeline_parallel: false
  gradient_accumulation_steps: 16
  # Memory optimization
  max_memory_allocated: "80%"  # Leave 20% buffer
  max_memory_cached: "70%"
  # GPU optimization
  cuda_visible_devices: "0,1,2,3"  # Specify GPUs
  gpu_memory_fraction: 0.9

# Production monitoring and alerting
monitoring:
  enabled: true
  # Resource monitoring
  cpu_threshold: 80  # %
  memory_threshold: 85  # %
  gpu_memory_threshold: 90  # %
  # Performance monitoring
  batch_processing_time_threshold: 5000  # ms
  memory_leak_detection: true
  # Alerting configuration
  alert_email: "alerts@yourcompany.com"
  alert_slack_webhook: ${SLACK_WEBHOOK_URL}
  alert_pagerduty_key: ${PAGERDUTY_KEY}
  # Health check intervals
  health_check_interval: 30  # seconds
  metrics_collection_interval: 60  # seconds

# Security configuration for production
security:
  # API security
  enable_https: true
  ssl_cert_path: "/etc/ssl/certs/prismrag.crt"
  ssl_key_path: "/etc/ssl/keys/prismrag.key"
  # Authentication
  enable_auth: true
  jwt_secret: ${JWT_SECRET}
  token_expiry: 3600  # 1 hour
  # Rate limiting
  rate_limit_requests: 100  # requests per minute
  rate_limit_window: 60  # seconds
  # Data security
  encrypt_data_at_rest: true
  encryption_key: ${ENCRYPTION_KEY}
  enable_audit_logging: true

# Scalability configuration
scalability:
  # Horizontal scaling
  max_instances: 10
  min_instances: 2
  scaling_cooldown: 300  # seconds
  # Load balancing
  load_balancer_enabled: true
  load_balancer_algorithm: "round_robin"
  # Auto-scaling triggers
  cpu_scaling_threshold: 70  # %
  memory_scaling_threshold: 75  # %
  request_queue_scaling_threshold: 1000  # requests

# Backup and recovery configuration
backup:
  enabled: true
  # Backup schedule
  backup_schedule: "0 2 * * *"  # Daily at 2 AM
  retention_days: 30
  # Backup targets
  backup_to_s3: true
  s3_bucket: "prismrag-backups"
  backup_to_gcs: false
  gcs_bucket: ""
  # Recovery settings
  auto_recovery: true
  recovery_time_objective: 3600  # 1 hour
  recovery_point_objective: 900  # 15 minutes

# High availability configuration
high_availability:
  enabled: true
  replication_factor: 3
  quorum_size: 2
  # Failover settings
  auto_failover: true
  failover_timeout: 30  # seconds
  # Cluster settings
  cluster_name: "prismrag-cluster"
  cluster_nodes: 3
  # Distributed training
  enable_distributed_training: true
  distributed_strategy: "ddp"  # Distributed Data Parallel

# Resource limits for production
resources:
  # CPU limits
  cpu_request: "4"
  cpu_limit: "8"
  # Memory limits
  memory_request: "16Gi"
  memory_limit: "32Gi"
  # GPU limits
  gpu_request: "1"
  gpu_limit: "2"
  # Storage limits
  storage_request: "100Gi"
  storage_limit: "200Gi"
  # Network limits
  network_bandwidth: "1Gbps"

# Experimental features for production
experimental:
  use_raft: false
  use_star: false
  use_llm_quoter: false
  enable_multilingual: false
  enable_domain_specific: true  # Enable domain-specific features
  # A/B testing
  enable_ab_testing: true
  ab_testing_traffic_percentage: 10  # %
  # Feature flags
  feature_flags:
    new_data_generation: false
    enhanced_evaluation: true
    real_time_monitoring: true

# Production-specific environment variables
environment:
  node_env: "production"
  debug: false
  testing: false
  # Deployment environment
  deployment_region: "us-west-2"
  availability_zone: "us-west-2a"
  # Service discovery
  service_discovery_enabled: true
  consul_host: "consul.service.consul"
  consul_port: 8500

# Version and deployment info
version: "1.0.0-production"
deployment_id: ${DEPLOYMENT_ID}
build_number: ${BUILD_NUMBER}
git_commit: ${GIT_COMMIT}
last_deployed: "2025-01-19T00:00:00Z"

# Production metadata
metadata:
  team: "ai-platform"
  environment: "production"
  tier: "critical"
  sla: "99.9%"
  business_unit: "research"
  cost_center: "ai-research-001"
  # Compliance
  compliance:
    gdpr: true
    hipaa: false
    soc2: true
  # Tags
  tags:
    - "ai"
    - "rag"
    - "production"
    - "critical"

# Production health checks
health_checks:
  liveness_path: "/health/live"
  readiness_path: "/health/ready"
  startup_path: "/health/startup"
  # Check intervals
  liveness_interval: 10
  readiness_interval: 5
  startup_timeout: 300
  # Dependency checks
  check_database: true
  check_cache: true
  check_external_apis: true

# Production metrics export
metrics_export:
  prometheus:
    enabled: true
    port: 9090
    path: "/metrics"
  statsd:
    enabled: false
    host: "localhost"
    port: 8125
  datadog:
    enabled: true
    api_key: ${DATADOG_API_KEY}
  new_relic:
    enabled: false
    license_key: ${NEW_RELIC_LICENSE_KEY}

# Production tracing
tracing:
  enabled: true
  jaeger:
    enabled: true
    host: "jaeger.service.consul"
    port: 6831
  zipkin:
    enabled: false
    host: "zipkin.service.consul"
    port: 9411
  # Sampling rate
  sampling_rate: 0.1  # 10% of requests

# Production error handling
error_handling:
  max_retry_attempts: 3
  retry_delay: 1000  # ms
  circuit_breaker_enabled: true
  circuit_breaker_threshold: 50  # % failure rate
  circuit_breaker_timeout: 30000  # ms
  # Error reporting
  sentry:
    enabled: true
    dsn: ${SENTRY_DSN}
  rollbar:
    enabled: false
    access_token: ${ROLLBAR_ACCESS_TOKEN}

# Production cache configuration
cache:
  redis:
    enabled: true
    host: "redis.service.consul"
    port: 6379
    password: ${REDIS_PASSWORD}
    database: 0
    # Cache TTLs
    model_cache_ttl: 3600  # 1 hour
    data_cache_ttl: 1800  # 30 minutes
    response_cache_ttl: 300  # 5 minutes
  memcached:
    enabled: false
    hosts: ["memcached.service.consul:11211"]
  # Local cache
  local_cache_size: 1000  # items
  local_cache_ttl: 300  # 5 minutes

# Production database configuration
database:
  postgresql:
    enabled: true
    host: "postgres.service.consul"
    port: 5432
    database: "prismrag"
    username: ${POSTGRES_USERNAME}
    password: ${POSTGRES_PASSWORD}
    # Connection pooling
    pool_size: 20
    max_overflow: 10
    pool_timeout: 30
    pool_recycle: 3600
  # MongoDB (for unstructured data)
  mongodb:
    enabled: false
    connection_string: ${MONGODB_CONNECTION_STRING}
    database: "prismrag"

# Production queue configuration
queue:
  rabbitmq:
    enabled: true
    host: "rabbitmq.service.consul"
    port: 5672
    username: ${RABBITMQ_USERNAME}
    password: ${RABBITMQ_PASSWORD}
    # Queue settings
    prefetch_count: 10
    message_ttl: 86400000  # 24 hours
    dead_letter_exchange: "dlx"
  # SQS (AWS)
  sqs:
    enabled: false
    queue_url: ${SQS_QUEUE_URL}
    region: "us-west-2"

# Production storage configuration
storage:
  s3:
    enabled: true
    bucket: "prismrag-data"
    region: "us-west-2"
    access_key: ${AWS_ACCESS_KEY_ID}
    secret_key: ${AWS_SECRET_ACCESS_KEY}
  # Google Cloud Storage
  gcs:
    enabled: false
    bucket: "prismrag-data"
    credentials: ${GCS_CREDENTIALS}
  # Azure Blob Storage
  azure:
    enabled: false
    container: "prismrag-data"
    connection_string: ${AZURE_CONNECTION_STRING}

# Production network configuration
network:
  # DNS settings
  dns_servers: ["8.8.8.8", "8.8.4.4"]
  # Firewall rules
  allowed_ips: ["10.0.0.0/8", "172.16.0.0/12", "192.168.0.0/16"]
  # Proxy settings
  http_proxy: ${HTTP_PROXY}
  https_proxy: ${HTTPS_PROXY}
  no_proxy: "localhost,127.0.0.1,.service.consul"

# Production timeouts
timeouts:
  http_request: 30000  # ms
  database_query: 10000  # ms
  external_api: 15000  # ms
  training_job: 86400000  # 24 hours
  generation_request: 60000  # ms

# Production rate limiting
rate_limits:
  api_requests: 1000  # requests per minute
  data_generation: 100  # generations per minute
  model_training: 2  # training jobs per hour
  evaluation: 50  # evaluations per minute

# Production maintenance windows
maintenance:
  enabled: true
  schedule: "Sun 02:00-04:00"
  timezone: "UTC"
  # Maintenance tasks
  tasks:
    - "database_backup"
    - "log_rotation"
    - "cache_clearing"
    - "model_reloading"

# Production rollback configuration
rollback:
  enabled: true
  max_versions: 5
  auto_rollback: true
  rollback_threshold: 5  # % error rate
  rollback_timeout: 300  # seconds

# Production cost optimization
cost_optimization:
  spot_instances: true
  reserved_instances: false
  auto_scaling: true
  # Cost alerts
  cost_alerts_enabled: true
  monthly_budget: 10000  # USD
  cost_alert_threshold: 80  # % of budget
  # Resource optimization
  auto_shutdown: true
  shutdown_after_hours: 4  # hours of inactivity
  # Storage optimization
  auto_cleanup: true
  cleanup_age_days: 7  # days
  cleanup_keep_versions: 3

# Production compliance and governance
compliance:
  # Data retention
  data_retention_days: 365
  log_retention_days: 90
  backup_retention_days: 30
  # Access controls
  enable_rbac: true
  admin_roles: ["admin", "superuser"]
  user_roles: ["user", "viewer"]
  # Audit logging
  audit_log_enabled: true
  audit_log_retention: 180  # days
  # Data classification
  data_classification: "confidential"
  # Regulatory compliance
  gdpr_compliant: true
  ccpa_compliant: true
  hipaa_compliant: false

# Production disaster recovery
disaster_recovery:
  enabled: true
  # Backup strategy
  backup_strategy: "daily_incremental_weekly_full"
  # Recovery objectives
  rto: 3600  # 1 hour recovery time objective
  rpo: 900   # 15 minutes recovery point objective
  # Multi-region deployment
  multi_region: false
  regions: ["us-west-2"]
  # Disaster recovery plan
  dr_plan_enabled: true
  dr_testing_interval: 90  # days

# Production capacity planning
capacity_planning:
  # Current capacity
  current_users: 1000
  expected_growth: 20  # % per month
  # Resource forecasting
  forecast_period: 12  # months
  # Scaling recommendations
  auto_scaling_recommendations: true
  # Capacity alerts
  capacity_alert_threshold: 75  # %

# Production performance targets
performance_targets:
  # Response time targets
  p95_response_time: 1000  # ms
  p99_response_time: 2000  # ms
  # Throughput targets
  requests_per_second: 100
  # Availability targets
  uptime_target: 99.9  # %
  # Error rate targets
  error_rate_target: 0.1  # %

# Production incident management
incident_management:
  enabled: true
  # Incident response
  response_time_target: 300  # seconds
  resolution_time_target: 3600  # seconds
  # On-call rotation
  on_call_rotation: "weekly"
  # Post-mortem process
  post_mortem_required: true
  post_mortem_timeframe: 7  # days

# Production change management
change_management:
  enabled: true
  # Change approval process
  approval_required: true
  approvers: ["team-lead", "product-manager"]
  # Deployment windows
  deployment_windows: ["Mon-Fri 10:00-16:00 UTC"]
  # Rollout strategy
  rollout_strategy: "canary"
  canary_percentage: 10  # %
  # Change documentation
  change_documentation_required: true

# Production service level objectives (SLOs)
slos:
  # Availability SLO
  availability: 99.9
  availability_measurement_period: 30  # days
  # Latency SLO
  latency_p95: 1000  # ms
  latency_measurement_period: 7  # days
  # Error budget
  error_budget: 0.1  # %
  # SLO violations
  slo_violation_alert: true
  violation_threshold: 5  # %

# Production feature flags
feature_flags:
  # Gradual rollout flags
  gradual_rollout:
    new_data_pipeline: 50  # %
    enhanced_evaluation: 100  # %
    real_time_monitoring: 25  # %
  # Environment-specific flags
  environment_specific:
    development: true
    staging: true
    production: false
  # User segment flags
  user_segments:
    internal_users: true
    beta_testers: 50  # %
    all_users: false

# Production external integrations
integrations:
  # Monitoring integrations
  datadog:
    enabled: true
    api_key: ${DATADOG_API_KEY}
  new_relic:
    enabled: false
    license_key: ${NEW_RELIC_LICENSE_KEY}
  # Alerting integrations
  pagerduty:
    enabled: true
    service_key: ${PAGERDUTY_SERVICE_KEY}
  opsgenie:
    enabled: false
    api_key: ${OPSGENIE_API_KEY}
  # Communication integrations
  slack:
    enabled: true
    webhook_url: ${SLACK_WEBHOOK_URL}
  teams:
    enabled: false
    webhook_url: ${TEAMS_WEBHOOK_URL}

# Production security scanning
security_scanning:
  # Vulnerability scanning
  vulnerability_scanning:
    enabled: true
    schedule: "0 0 * * 0"  # Weekly on Sunday
    severity_threshold: "high"
  # Dependency scanning
  dependency_scanning:
    enabled: true
    schedule: "0 0 * * *"  # Daily
  # Container scanning
  container_scanning:
    enabled: true
    schedule: "0 0 * * 0"  # Weekly on Sunday
  # Secret detection
  secret_detection:
    enabled: true
    schedule: "0 0 * * *"  # Daily

# Production data governance
data_governance:
  # Data quality
  data_quality_checks:
    enabled: true
    schedule: "0 2 * * *"  # Daily at 2 AM
    thresholds:
      completeness: 95  # %
      accuracy: 98  # %
      consistency: 97  # %
  # Data lineage
  data_lineage:
    enabled: true
    tracking_level: "detailed"
  # Data catalog
  data_catalog:
    enabled: true
    auto_discovery: true

# Production end-of-file marker
# This configuration is optimized for production deployment
# Last updated: 2025-01-19
# Configuration version: 1.0.0-production