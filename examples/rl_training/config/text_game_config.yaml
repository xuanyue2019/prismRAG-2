# 文本游戏强化学习配置

# 训练参数
training:
  algorithm: "ppo"                   # 训练算法: ppo, a2c, dqn
  learning_rate: 0.0003              # 学习率
  gamma: 0.99                        # 折扣因子
  clip_epsilon: 0.2                  # PPO 裁剪参数
  entropy_coef: 0.01                 # 熵系数（鼓励探索）
  value_coef: 0.5                    # 价值函数系数
  max_grad_norm: 0.5                 # 梯度裁剪
  
  # 训练周期
  total_timesteps: 1000000           # 总时间步数
  n_steps: 2048                      # 每个更新周期的步数
  batch_size: 64                     # 批量大小
  n_epochs: 10                       # 每个更新周期的迭代次数
  
  # 设备配置
  device: "auto"                     # auto, cpu, cuda
  num_envs: 4                        # 并行环境数量

# 环境参数
environment:
  env_id: "TextGame-v1"              # 环境ID
  max_steps: 1000                    # 每个回合最大步数
  reward_scale: 1.0                  # 奖励缩放因子
  
  # 难度设置
  difficulty: "medium"               # easy, medium, hard
  scenario_files:                    # 场景文件列表
    - "data/text_game_scenarios/beginner_1.json"
    - "data/text_game_scenarios/beginner_2.json"
    - "data/text_game_scenarios/intermediate_1.json"
  
  # 观察空间
  obs_type: "text"                   # text, embedding, both
  max_text_length: 512               # 最大文本长度
  use_history: true                  # 是否使用历史记录
  history_length: 10                 # 历史记录长度

# 模型架构
model:
  # 文本编码器
  text_encoder:
    type: "transformer"              # transformer, lstm, cnn
    hidden_size: 512                 # 隐藏层大小
    num_layers: 3                    # 层数
    num_heads: 8                     # 注意力头数
    dropout: 0.1                     # Dropout 率
    
  # 策略网络
  policy_network:
    hidden_sizes: [256, 128]         # 隐藏层尺寸
    activation: "relu"               # 激活函数
    use_layer_norm: true             # 是否使用层归一化
    
  # 价值网络
  value_network:
    hidden_sizes: [256, 128]         # 隐藏层尺寸
    activation: "relu"               # 激活函数
    use_layer_norm: true             # 是否使用层归一化

# 奖励设置
rewards:
  # 基础奖励
  completion_reward: 10.0            # 完成任务奖励
  item_collection_reward: 2.0        # 收集物品奖励
  invalid_action_penalty: -1.0       # 无效动作惩罚
  step_penalty: -0.01                # 步数惩罚
  
  # 额外奖励
  exploration_bonus: 0.1             # 探索新区域奖励
  puzzle_solving_bonus: 5.0          # 解谜奖励
  efficient_path_bonus: 3.0          # 高效路径奖励
  
  # 奖励塑造
  use_reward_shaping: true           # 是否使用奖励塑造
  shaping_coef: 0.5                  # 奖励塑造系数

# 课程学习
curriculum:
  enabled: true                      # 是否启用课程学习
  levels:
    - name: "beginner"
      difficulty: "easy"
      scenarios: ["beginner_*.json"]
      min_success_rate: 0.8          # 升级所需最小成功率
      max_training_episodes: 1000    # 最大训练回合数
      
    - name: "intermediate"
      difficulty: "medium"
      scenarios: ["intermediate_*.json"]
      min_success_rate: 0.7
      max_training_episodes: 2000
      
    - name: "advanced"
      difficulty: "hard"
      scenarios: ["advanced_*.json"]
      min_success_rate: 0.6
      max_training_episodes: 3000

# 监控和日志
monitoring:
  # 日志设置
  log_interval: 10                   # 日志记录间隔（回合数）
  verbose: 1                         # 详细程度：0-2
  
  # 检查点
  save_interval: 100                 # 模型保存间隔（回合数）
  save_best_only: true               # 只保存最佳模型
  checkpoint_dir: "checkpoints/"     # 检查点目录
  
  # 评估
  eval_interval: 50                  # 评估间隔（回合数）
  eval_episodes: 10                  # 每次评估的回合数
  eval_envs: 2                       # 评估环境数量
  
  # 可视化
  use_tensorboard: true              # 是否使用 TensorBoard
  use_wandb: false                   # 是否使用 Weights & Biases
  project_name: "agent-lightning-rl" # 项目名称

# 超参数优化
hyperparameter_optimization:
  enabled: false                     # 是否启用超参数优化
  n_trials: 20                       # 试验次数
  search_space:
    learning_rate:
      type: "loguniform"
      low: 1e-5
      high: 1e-3
    gamma:
      type: "uniform"
      low: 0.9
      high: 0.999
    clip_epsilon:
      type: "uniform"
      low: 0.1
      high: 0.3

# 实验设置
experiment:
  name: "text_game_ppo"              # 实验名称
  seed: 42                           # 随机种子
  description: "PPO training for text game agent"
  tags: ["text-game", "ppo", "rl"]